{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict dual models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from models import unetpp_level_1, unet_level_2\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU sample processing: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12977154852435322817\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9992663860\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10846868465568318858\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(\"GPU sample processing: \")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 912\n",
    "IMG_WIDTH = 912\n",
    "CROP_HEIGHT = 228\n",
    "CROP_WIDTH = 228\n",
    "\n",
    "BURNED_PIXEL_VALUE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WEIGHT_NETWORK_1 = \"C:/Users/windows/Desktop/Research/3. Code/0.GITHUB-CODE/forest-fire-damage-mapping/[Project]_Model_weights/network_1_weights/checkpoint\"\n",
    "PATH_WEIGHT_NETWORK_2 = \"C:/Users/windows/Desktop/Research/3. Code/0.GITHUB-CODE/forest-fire-damage-mapping/[Project]_Model_weights/network_2_weights/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TESTING_1 = \"C:/Users/windows/Desktop/Research/3. Code/0.GITHUB-CODE/forest-fire-damage-mapping/sample_data/sample_location_2_data/Img/\"\n",
    "PATH_MASK_TESTING_1 = \"C:/Users/windows/Desktop/Research/3. Code/0.GITHUB-CODE/forest-fire-damage-mapping/sample_data/sample_location_2_data/Label/\"\n",
    "\n",
    "PATH_TESTING_2 = \"C:/Users/windows/Desktop/Research/3. Code/6. UnetFire/ImgLabel/official_data_10.6/location_2_crop_for_2nd_network/Img/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SAVE_PREDICTION = \"C:/Users/windows/Desktop/Research/3. Code/0.GITHUB-CODE/forest-fire-damage-mapping/sample_data/sample_location_2_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_level, path_weight, model_summary = False):\n",
    "    if model_level == 1:\n",
    "        model = unetpp_level_1.create_model()\n",
    "        model.load_weights(path_weight)\n",
    "    elif model_level == 2:\n",
    "        model = unet_level_2.create_model()\n",
    "        model.load_weights(path_weight)\n",
    "    if model_summary:\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_level_1 = load_model(model_level = 1, path_weight = PATH_WEIGHT_NETWORK_1, model_summary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_level_2 = load_model(model_level = 2, path_weight = PATH_WEIGHT_NETWORK_2, model_summary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.25\n",
    "gamma = 2\n",
    "def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
    "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
    "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
    "\n",
    "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(\n",
    "        -logits)) * (weight_a + weight_b) + logits * weight_b\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(),\n",
    "                              1 - tf.keras.backend.epsilon())\n",
    "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
    "\n",
    "    loss = focal_loss_with_logits(logits=logits, targets=y_true,\n",
    "                                  alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (\n",
    "                K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(\n",
    "        K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss_final(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "\n",
    "    y_true_f = y_true.reshape(-1)\n",
    "    y_pred_f = y_pred.reshape(-1)\n",
    "    intersection = np.sum((y_true_f * y_pred_f))\n",
    "    \n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_level_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4), loss = focal_loss, metrics =[dice_coef, sensitivity, specificity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_1_prediction(path_img_level_1, path_mask_level_1):\n",
    "    img_level_1 = load_img(path_img_level_1, grayscale=False, target_size=[IMG_HEIGHT, IMG_WIDTH])\n",
    "    mask_level_1 = load_img(path_mask_level_1, grayscale=True, target_size=[IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Preprocessing image\n",
    "    img_level_1 = img_to_array(img_level_1)\n",
    "    img_level_1 = img_level_1.astype('float32')\n",
    "    img_level_1 /= 255\n",
    "    img_level_1 = img_level_1.reshape(1,IMG_HEIGHT,IMG_WIDTH,3)\n",
    "    # Preprocessing mask\n",
    "    mask_level_1 = img_to_array(mask_level_1)\n",
    "    mask_level_1 = mask_level_1.astype('float32')\n",
    "    mask_level_1 /= np.max(mask_level_1)\n",
    "    \n",
    "    where_are_NaNs = np.isnan(mask_level_1)\n",
    "    mask_level_1[where_are_NaNs] = 0\n",
    "    mask_level_1 = mask_level_1.reshape(1,IMG_HEIGHT,IMG_WIDTH,1)\n",
    "    # Network 1 prediction\n",
    "    result_level_1 = model_level_1.predict(img_level_1)\n",
    "    # Reshape predicted result\n",
    "    result_level_1[0,:,:,0][result_level_1[0,:,:,0] > 0.5] = 1\n",
    "    result_level_1[0,:,:,0][result_level_1[0,:,:,0] <= 0.5] = 0\n",
    "    result_level_1 = result_level_1.reshape(IMG_HEIGHT,IMG_WIDTH)\n",
    "    # Model evaluate\n",
    "    _, dice_coef, sensitivity, specificity = model_level_1.evaluate(img_level_1, mask_level_1, verbose = 0)\n",
    "    return dice_coef, sensitivity, specificity, result_level_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_crop_num(result):\n",
    "    crop_num = 1\n",
    "    save_crop_burned_num = []\n",
    "    for row in np.arange(0, IMG_HEIGHT, CROP_HEIGHT):\n",
    "        for col in np.arange(0, IMG_WIDTH, CROP_WIDTH):\n",
    "            crop_window = result[col:col+CROP_HEIGHT, row:row+CROP_WIDTH]\n",
    "            if crop_window.any() == 1:\n",
    "                save_crop_burned_num.append(crop_num)\n",
    "            crop_num += 1\n",
    "    return save_crop_burned_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_2_fine_tune(num_img, save_crop_burned_num):\n",
    "    final_prediction = np.zeros((IMG_HEIGHT, IMG_WIDTH))\n",
    "    crop_num = 1\n",
    "    scale_height = 128\n",
    "    scale_width = 128\n",
    "    for row in np.arange(0, IMG_HEIGHT, CROP_HEIGHT):\n",
    "        for col in np.arange(0, IMG_WIDTH, CROP_WIDTH):\n",
    "            if crop_num in save_crop_burned_num:\n",
    "#                 print(\"Fine tune damage map\")\n",
    "                path_img_level_2 = PATH_TESTING_2 + 'img{}crop{}.png'.format(num_img, crop_num)\n",
    "                img_level_2 = load_img(path_img_level_2, grayscale=False, target_size=[scale_height, scale_width])\n",
    "                img_level_2 = img_to_array(img_level_2)\n",
    "                img_level_2 = img_level_2.astype('float32')\n",
    "                img_level_2 /= 255\n",
    "                img_level_2 = img_level_2.reshape(1,scale_height,scale_width,3)\n",
    "                # Network 2 predict path-level images\n",
    "                result_level_2 = model_level_2.predict(img_level_2)\n",
    "                result_level_2[0,:,:,0][result_level_2[0,:,:,0] > 0.5] = 1\n",
    "                result_level_2[0,:,:,0][result_level_2[0,:,:,0] <= 0.5] = 0\n",
    "                result_level_2 = result_level_2.reshape(scale_height,scale_width)\n",
    "                # Resize \n",
    "                result_level_2_resize = cv2.resize(result_level_2, (CROP_HEIGHT, CROP_WIDTH), interpolation=cv2.INTER_LINEAR)\n",
    "                final_prediction[col:col+CROP_HEIGHT, row:row+CROP_WIDTH] = result_level_2_resize\n",
    "            elif crop_num not in save_crop_burned_num:\n",
    "                final_prediction[col:col+CROP_HEIGHT, row:row+CROP_WIDTH] = np.zeros(final_prediction[col:col+CROP_HEIGHT, row:row+CROP_WIDTH].shape)\n",
    "            crop_num += 1\n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_models_prediction(num_testing= 720, visualize_compare_results = True, save_prediction = False):\n",
    "    dice_coef_save_level_1 = []\n",
    "    sensitivity_save_level_1 = []\n",
    "    specificity_save_level_1 = []\n",
    "    \n",
    "    dice_coef_save_final= []\n",
    "    sensitivity_save_final = []\n",
    "    specificity_save_final = []\n",
    "    for num_img in tqdm (range(697, num_testing+1)):\n",
    "#     for num_img in tqdm (range(121, num_testing+1)):\n",
    "#     for num_img in tqdm (np.array([num_testing])):\n",
    "        # Load testing image for level 1 network\n",
    "        path_img_level_1 = PATH_TESTING_1 + \"img{}.png\".format(num_img) \n",
    "        path_mask_level_1 = PATH_MASK_TESTING_1 + \"label{}.png\".format(num_img) \n",
    "        \n",
    "        img_level_1 = load_img(path_img_level_1, grayscale=False, target_size=[IMG_HEIGHT, IMG_WIDTH])\n",
    "        mask_level_1 = load_img(path_mask_level_1, grayscale=True, target_size=[IMG_HEIGHT, IMG_WIDTH])\n",
    "        mask_level_1 = img_to_array(mask_level_1)\n",
    "        mask_level_1 = mask_level_1.astype('float32')\n",
    "        \n",
    "#         print(np.unique(mask_level_1))\n",
    "\n",
    "        mask_level_1 /= np.max(mask_level_1)\n",
    "        where_are_NaNs = np.isnan(mask_level_1)\n",
    "        mask_level_1[where_are_NaNs] = 0\n",
    "        \n",
    "        mask_level_1 = mask_level_1.reshape(IMG_HEIGHT,IMG_WIDTH)\n",
    "        \n",
    "        if visualize_compare_results:\n",
    "            plt.figure(figsize=(10,5))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(img_level_1)\n",
    "            plt.title('Input testing images')\n",
    "        # Network 1 predict \n",
    "        dice_coef, sensitivity, specificity, result_level_1 = network_1_prediction(path_img_level_1,path_mask_level_1)\n",
    "#         print(result_level_1.shape)\n",
    "        # Save model evaluation metrics\n",
    "        dice_coef_save_level_1.append(dice_coef)\n",
    "        sensitivity_save_level_1.append(sensitivity)\n",
    "        specificity_save_level_1.append(specificity)\n",
    "        # Extract crop window with burned pixels\n",
    "        save_crop_burned_num = extract_crop_num(result_level_1)\n",
    "        # Network 2 fine tune\n",
    "        final_prediction = network_2_fine_tune(num_img, save_crop_burned_num)\n",
    "        final_prediction[final_prediction > 0.5] = 1\n",
    "        final_prediction[final_prediction <= 0.5] = 0\n",
    "        # Visualize\n",
    "        if visualize_compare_results:\n",
    "            \n",
    "            final_result = np.ma.masked_where(final_prediction == BURNED_PIXEL_VALUE, final_prediction)\n",
    "            cmap = matplotlib.cm.Greys  \n",
    "            cmap.set_bad(color='black')\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(final_result, cmap = cmap)\n",
    "            plt.title('Dual model prediction')\n",
    "            plt.show()\n",
    "        # Save prediction\n",
    "        if save_prediction:\n",
    "            path_save = PATH_SAVE_PREDICTION + \"predict{}.png\".format(num_img)\n",
    "            cv2.imwrite(path_save,final_prediction*255)\n",
    "            \n",
    "        tn_, fp_, fn_, tp_ = confusion_matrix(mask_level_1.reshape(-1), final_prediction.reshape(-1), labels=[0,1]).ravel()\n",
    "        specificity = tn_ / (tn_+fp_)\n",
    "        sensitivity = tp_ / (tp_+fn_)\n",
    "        dice_coef_final =  dice_loss_final(mask_level_1, final_prediction)\n",
    "        \n",
    "        dice_coef_save_final.append(dice_coef_final)\n",
    "        sensitivity_save_final.append(sensitivity)\n",
    "        specificity_save_final.append(specificity)\n",
    "        \n",
    "    return dice_coef_save_final, sensitivity_save_final, specificity_save_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:42<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "dice_coef_save_final, sensitivity_save_final, specificity_save_final = dual_models_prediction(num_testing=720, visualize_compare_results = False, save_prediction = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of final \n",
      "Dice coef = 0.789062636574695\n",
      "Sensitivity = 0.1349067774682086\n",
      "Specificity = 0.9855287802647078\n"
     ]
    }
   ],
   "source": [
    "sensitivity_save_final = np.array(sensitivity_save_final)\n",
    "where_are_NaNs = np.isnan(sensitivity_save_final)\n",
    "sensitivity_save_final[where_are_NaNs] = 0\n",
    "\n",
    "specificity_save_final = np.array(specificity_save_final)\n",
    "where_are_NaNs = np.isnan(specificity_save_final)\n",
    "specificity_save_final[where_are_NaNs] = 0\n",
    "\n",
    "print(\"Performance of final \")\n",
    "print(\"Dice coef = {}\".format(np.mean(np.array(dice_coef_save_final))))\n",
    "print(\"Sensitivity = {}\".format(np.mean(np.array(sensitivity_save_final))))\n",
    "print(\"Specificity = {}\".format(np.mean(np.array(specificity_save_final))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}